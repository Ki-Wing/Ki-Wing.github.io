---
title: Chap06
author: kiwing
date: 2023-04-21 20:55:00 +0800
categories: [AI, NNDL]
tags: [NNDL]
pin: false
img_path: '/posts/20180809'
---
# CHAPTER6. Deep learning

<br>

<p align="center"><img width="100%" alt="1" src="https://user-images.githubusercontent.com/127064655/234730343-2c6c08a7-b1fc-4dc2-be27-7e9ba4d0d98b.png"></p>

## Introducing convolutional networks

- Convolutional neural networks(CNN)? 

=> Used to classify, recognize, and process different types of data, such as images, videos, voice, and text // Extract&classify features from input images

=> Each layer applies multiple filters or kernels to the input image (convolution operation)

=> Reduce the size of feature maps to save computational costs and prevent overfitting (pooling operation)

- Convolutional neural networks use three basic ideas: local receptive fields, shared weights, and pooling

**Local receptive fields**

<img width="100%" alt="2" src="https://user-images.githubusercontent.com/127064655/234738104-3cf72733-2a63-4387-873e-4e0b328efab2.png">

- Inputs as a 28√ó28 square of neurons

<p align="center"><img width="100%" alt="3" src="https://user-images.githubusercontent.com/127064655/234739221-b2800ee9-b9e7-4d47-8f59-87c63cfd830d.png"></p>

- Each neuron in the first hidden layer connects to a small area of the input neuron

- LOCAL RECEPTIVE FIELD (small window on the input pixel)

<p align="center"><img width="100%" alt="2" src="https://user-images.githubusercontent.com/127064655/236974275-3136db2d-2b07-401b-b406-662828b0fc94.gif"></p>

<br> <br>

**shared weights and biases**

<p align="center"><img width="100%" alt="4" src="https://user-images.githubusercontent.com/127064655/236714011-bd9e1316-013d-4e60-8c24-1a3395c9fbf5.png"></p>

- j,kth hidden neuron // all the neurons in the first hidden layer detect exactly the same feature

- Feature : type of input pattern that causes the neuron to activate the features detected by the hidden neuron

- Feature map : output map generated in the process of extracting features from an image or other data

- The shared weights and bias are often said to define a kernel or filter

<br>

<p align="center"><img width="100%" alt="5" src="https://user-images.githubusercontent.com/127064655/236718056-c28986e8-5f20-4339-ad63-b2214ec47303.png"></p>

- Each map is displayed as a 5x5 block image corresponding to the 5x5 weight of the local receive field

- White blocks mean smaller (usually more negative) weights

- Darker blocks mean larger weight (feature maps respond more to corresponding input pixels)

- üëçüèª Can greatly reduce the number of parameters

<br>

**Pooling layers**

<img width="100%" alt="6" src="https://user-images.githubusercontent.com/127064655/236732708-365a8f36-434b-4bea-84f7-a743e46fbdc4.png">

- Max-pooling layers 

=> Scan the input image and extract the maximum value from each area to generate an output

=> Increase the invariance of the movement, rotation, and size conversion of images

<p align="center"><img width="100%" alt="6" src="https://user-images.githubusercontent.com/127064655/236974085-391e2b84-a9b3-4afd-845a-3a3b2dca58ec.png"></p>

- L2 pooling 

=> Calculate the L2 norm in each area of the input image to generate an output

=> Retain information about the size and orientation of each pixel in the input image.



<br>

## Convolutional neural networks in practice

<p align="center"><img width="80%" alt="8" src="https://user-images.githubusercontent.com/127064655/236739516-4ad80cbd-17e0-42a2-9b19-60717aa5c0ba.png"></p>

<br>

## Recent progress in image recognition

**[The 2012 LRMD paper](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/38115.pdf)**

<p align="center"><img width="100%" alt="9" src="https://user-images.githubusercontent.com/127064655/236753374-b69b875f-e13d-4e7a-b071-fee55a1eec83.png"></p>

- "Building high-level features using large scale unsupervised learning"

- Collect large, unlabeled image datasets and use them to pre-learn neural networks

- Fine-tuning pre-learned neural networks to extract high-level features that can be used for tasks such as image classification, retrieval, and object recognition

- 16 million full color images, in 20 thousand categories // best neurons : 81.7%

<br>

**[The 2012 KSH paper](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)**

<p align="center"><img width="100%" alt="10" src="https://user-images.githubusercontent.com/127064655/236760525-1525e333-aa8f-4a40-8e69-86c75c24db7f.jpeg"></p>

- "ImageNet Classification with Deep Convolutional Neural Networks"

- Uses ImageNet dataset, a dataset of over 15 million labels in 22,000 categories and high-resolution images

- With 60 million parameters and 650,000 neurons consists of five convolutional neural network layers

- ImageNet LSVRC-2012 contest wins with 15.3% error rate

- First five are convolutional layers, two are fully connected layers, output layer is 1000-unit softmax layer

<br>

**[The 2014 ILSVRC competition](https://arxiv.org/pdf/1409.4842.pdf)**

- "Going Deeper with Convolutions" 

<p align="center"><img width="100%" alt="11" src="https://user-images.githubusercontent.com/127064655/236766501-d66561ff-f683-4da6-b822-bdb4350ad049.png"></p>

- inception module // Use 1x1, 3x3, and 5x5 filters simultaneously to learn information of various sizes and depths

- The main benefits of architecture 

=> It is possible to improve the performance of the model by increasing the number of units without increasing computing operations

=> Visual information is processed into multiple scales through various 1x1, 3x3, and 5x5 convolution operations, allowing the next layer to simultaneously abstract the characteristics of different scales

<img width="50%" alt="12" src="https://user-images.githubusercontent.com/127064655/236765540-74e71b58-fa90-43fb-80fb-fb8744425641.jpeg">

- The lower layer follows the basic cnn structure for efficient use of memory, and the use of the insensitivity module is repeated in the next step

<br>

<br>

## Other approaches to deep neural nets

**RNNs(Recurrent neural networks)**

- An artificial neural network model for processing sequence data.

- Each time step, the input data and the hidden state value at the previous time point are received as inputs and the current hidden state value is output

<p align="center"><img width="100%" alt="12" src="https://user-images.githubusercontent.com/127064655/236783785-26580390-5a7e-413d-b778-d0e75aeefd4b.png"></p>

- Whh * (x2) + Wxh * (x1) + b

=> Input vector enters hidden layer

=> Output vector generated from hidden layer

=> Exit the hidden layer and re-enter the hidden layer

<br>

**LSTM(Long Short-Term Memory models)**

<p align="center"><img width="100%" alt="12" src="https://user-images.githubusercontent.com/127064655/236963454-f146fe9d-60f5-45d3-931a-c1c0512e1d56.png"></p>

1) input 

- Determines how much current information to remember

- The hidden state of the previous layer is multiplied by tanh and the new information is multiplied by sigmoid active function

- Multiply the new attribute by sigmoid to determine how much new information will be used as a result between 0 and 1

2) forget

- Input and hidden state are multiplied by different weights and then passed through the sigmoid active function (0~1)

- Create a new cell state by multiplying the cell state of the previous time step

3) output

- Multiply the previous hidden state value and the input value by different weights and pass the sigmoid active function

- Output value and the current Cell state value are multiplied by the value passed by the tanh active function to make a hidden state.

[nodejs]: https://nodejs.org/
[starter]: https://github.com/cotes2020/chirpy-starter
[pages-workflow-src]: https://docs.github.com/en/pages/getting-started-with-github-pages/configuring-a-publishing-source-for-your-github-pages-site#publishing-with-a-custom-github-actions-workflow
[latest-tag]: https://github.com/cotes2020/jekyll-theme-chirpy/tags
